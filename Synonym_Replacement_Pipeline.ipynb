{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnhTY2O83DO9",
        "outputId": "4b8adc69-ead5-45ed-e3c4-7d7368a97854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXUEbj9Vk7Ca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from tqdm import tqdm as progressbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6noPijzXs1Di",
        "outputId": "9b319656-ff83-44b0-8bab-2edcd73415cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2H3c8EM8CUB"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHgZfHvf8D4K"
      },
      "outputs": [],
      "source": [
        "sentences1 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Nikta/Ad Paraphrasing/Bazarol/preprocess1.csv')\n",
        "sentences2 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Nikta/Ad Paraphrasing/Bazarol/preprocess2.csv')\n",
        "sentences1.drop([\"Unnamed: 0\"], axis=1,inplace=True)\n",
        "sentences2.drop([\"Unnamed: 0\"], axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEJpRBwtlW0W"
      },
      "outputs": [],
      "source": [
        "test = sentences1[10:15]\n",
        "test.reset_index(drop=True,inplace=True)\n",
        "test2 = sentences2[10:15]\n",
        "test2.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-XSNar12-xp"
      },
      "source": [
        "# POS (ensemble 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZN2H0YAV3Co5",
        "outputId": "06f0568d-5b30-4961-f3e6-1f93c7bb5226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/MohammadForouhesh/crf-pos-persian.git\n",
            "  Cloning https://github.com/MohammadForouhesh/crf-pos-persian.git to /tmp/pip-req-build-2rw5w3hg\n",
            "  Running command git clone -q https://github.com/MohammadForouhesh/crf-pos-persian.git /tmp/pip-req-build-2rw5w3hg\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sklearn-crfsuite>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from crf-pos==2.2.2) (0.3.6)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.7/dist-packages (from crf-pos==2.2.2) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from crf-pos==2.2.2) (1.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.7/dist-packages (from crf-pos==2.2.2) (2.28.1)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from crf-pos==2.2.2) (0.2.1)\n",
            "Requirement already satisfied: coverage>=6.2 in /usr/local/lib/python3.7/dist-packages (from crf-pos==2.2.2) (6.4.2)\n",
            "Collecting nltk>=3.6.6\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=58.0.4 in /usr/local/lib/python3.7/dist-packages (from crf-pos==2.2.2) (63.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1->crf-pos==2.2.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.6->crf-pos==2.2.2) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.6->crf-pos==2.2.2) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.6->crf-pos==2.2.2) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.6->crf-pos==2.2.2) (1.1.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->crf-pos==2.2.2) (21.4.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->crf-pos==2.2.2) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->crf-pos==2.2.2) (2.0.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->crf-pos==2.2.2) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->crf-pos==2.2.2) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->crf-pos==2.2.2) (21.3)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.5->crf-pos==2.2.2) (1.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=6.2.5->crf-pos==2.2.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=6.2.5->crf-pos==2.2.2) (3.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->crf-pos==2.2.2) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->crf-pos==2.2.2) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->crf-pos==2.2.2) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->crf-pos==2.2.2) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->crf-pos==2.2.2) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->crf-pos==2.2.2) (1.5.4)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->crf-pos==2.2.2) (1.21.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite>=0.3.6->crf-pos==2.2.2) (0.8.10)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite>=0.3.6->crf-pos==2.2.2) (0.9.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest>=6.2.5->crf-pos==2.2.2) (3.0.9)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.3\n",
            "    Uninstalling nltk-3.3:\n",
            "      Successfully uninstalled nltk-3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "hazm 0.7.0 requires nltk==3.3, but you have nltk 3.7 which is incompatible.\u001b[0m\n",
            "Successfully installed nltk-3.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install git+https://github.com/MohammadForouhesh/crf-pos-persian.git "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05bcMR2n3egw"
      },
      "outputs": [],
      "source": [
        "from crf_pos.pos_tagger.wapiti import WapitiPosTagger\n",
        "pos_tagger = WapitiPosTagger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Swi6eXTt1a0"
      },
      "outputs": [],
      "source": [
        "def pos(text):\n",
        "  vwords = []\n",
        "  poss = pos_tagger[text]\n",
        "  for tup in poss:\n",
        "    if  tup[1] == 'ADV' or tup[1] == 'ADJ' or tup[1] == 'INT' or tup[1] == 'CONJ':\n",
        "      vwords.append(tup[0])\n",
        "  return vwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQTLcRK45T5y"
      },
      "source": [
        "# NER (union 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgDif6tx_JLX"
      },
      "outputs": [],
      "source": [
        "# 3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvd-aHCQltup"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcOUGGsOltw6",
        "outputId": "ab56b0e5-7687-4ab6-f922-eff20e558c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "crf-pos 2.2.2 requires nltk>=3.6.6, but you have nltk 3.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -qU hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCUl-nP2ltzK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import hazm\n",
        "\n",
        "import transformers \n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from transformers import TFAutoModelForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwCME1-ir-m9",
        "outputId": "e84f9ed6-ebd2-4e42-b4c5-f8dadc303254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at HooshvareLab/bert-base-parsbert-armanner-uncased were not used when initializing TFBertForTokenClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-armanner-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model_namea = 'HooshvareLab/bert-base-parsbert-armanner-uncased'\n",
        "configa = AutoConfig.from_pretrained(model_namea)\n",
        "tokenizera = AutoTokenizer.from_pretrained(model_namea)\n",
        "modela = TFAutoModelForTokenClassification.from_pretrained(model_namea)\n",
        "labelsa = list(configa.label2id.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE5dtk-2r-pv",
        "outputId": "170aaa09-5dca-47d4-f10b-b1008fcefc72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at HooshvareLab/bert-base-parsbert-peymaner-uncased were not used when initializing TFBertForTokenClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-peymaner-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model_namep = 'HooshvareLab/bert-base-parsbert-peymaner-uncased'\n",
        "configp = AutoConfig.from_pretrained(model_namep)\n",
        "tokenizerp = AutoTokenizer.from_pretrained(model_namep)\n",
        "modelp = TFAutoModelForTokenClassification.from_pretrained(model_namep)\n",
        "labelsp = list(configp.label2id.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlhgk0Wrr-ty",
        "outputId": "e846d3dd-c33c-4011-8598-5cc945e06457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at HooshvareLab/bert-base-parsbert-ner-uncased were not used when initializing TFBertForTokenClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-ner-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model_namen = 'HooshvareLab/bert-base-parsbert-ner-uncased'\n",
        "confign = AutoConfig.from_pretrained(model_namen)\n",
        "tokenizern = AutoTokenizer.from_pretrained(model_namen)\n",
        "modeln = TFAutoModelForTokenClassification.from_pretrained(model_namen)\n",
        "labelsn = list(confign.label2id.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7xI0Jmvlt3a"
      },
      "outputs": [],
      "source": [
        "def ner_model(text, model,tokenizer,labels):\n",
        "  tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "  inputs = tokenizer.encode(text, return_tensors=\"tf\")\n",
        "  outputs = model(inputs)[0]\n",
        "  predictions = tf.argmax(outputs, axis=2)\n",
        "  predictions = [(token, labels[prediction]) for token, prediction in zip(tokens, predictions[0].numpy())]\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzCO7Mrplg0H"
      },
      "outputs": [],
      "source": [
        "def ner(text):\n",
        "  #arman\n",
        "  pred_arman = ner_model(text,modela,tokenizera,labelsa)\n",
        "  #peyma\n",
        "  pred_peyma = ner_model(text,modelp,tokenizerp,labelsp)\n",
        "  #ner\n",
        "  pred_ner = ner_model(text,modeln,tokenizern,labelsn)\n",
        "  vwords = []\n",
        "  tokens = word_tokenize(text)\n",
        "  for word in tokens:\n",
        "    ne = False\n",
        "    for tup in pred_arman:\n",
        "      if tup[0] == word:\n",
        "        if tup[1]!='O':\n",
        "          # print(tup[0])\n",
        "          # print(tup[1])\n",
        "          # print('-------')\n",
        "          ne=True\n",
        "    for tup in pred_peyma:\n",
        "      if tup[0] == word:\n",
        "        if tup[1]!='O':\n",
        "          # print(tup[0])\n",
        "          # print(tup[1])\n",
        "          # print('-------')\n",
        "          ne=True\n",
        "    for tup in pred_ner:\n",
        "      if tup[0] == word:\n",
        "        if tup[1]!='O':\n",
        "          # print(tup[0])\n",
        "          # print(tup[1])\n",
        "          # print('-------')\n",
        "          ne=True\n",
        "    if ne == False:\n",
        "      vwords.append(word)\n",
        "  return vwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQwMuIiswAx1"
      },
      "source": [
        "# Intersection of valid POS and NER "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUYWhnvYtp3w"
      },
      "outputs": [],
      "source": [
        "def intersection(lst1, lst2):\n",
        "    lst3 = [value for value in lst1 if value in lst2]\n",
        "    return lst3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8cRnctIO3eK"
      },
      "source": [
        "# Cleaning Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N7G7CDixEOY"
      },
      "outputs": [],
      "source": [
        "enc = pd.read_excel('/content/drive/My Drive/Colab Notebooks/Nikta/Ad Paraphrasing/enc.xlsx',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8iu5xrr9_FO"
      },
      "outputs": [],
      "source": [
        "def custom_tokenize(t):\n",
        "  word = ''\n",
        "  tokens = []\n",
        "  for i in t:\n",
        "    if i == ',':\n",
        "      if word != ' ':\n",
        "        tokens.append(word)\n",
        "      word=''\n",
        "      continue\n",
        "    if i == '&':\n",
        "      break\n",
        "    else:\n",
        "      word = word+i\n",
        "  if word != ' ':\n",
        "    tokens.append(word)\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwUsr20I23kb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def synonyms(enc_row):\n",
        "  if enc_row:\n",
        "    syn = []\n",
        "    output = re.sub(r'[A-Za-z]+','', enc_row)\n",
        "    output = re.sub(r'[0-9]+',',', output)\n",
        "    output = output.replace('\\u200c','-')\n",
        "    output = output.replace('،',',')\n",
        "    output.rstrip()\n",
        "    # print(output)\n",
        "    # # tok = word_tokenize(output)\n",
        "    # # clean_tokens=[]\n",
        "    # # for token in tok:\n",
        "    # #   #punctuation\n",
        "    # #   textt = re.sub(r'[^\\w\\s]', '', tok)\n",
        "    # #   #latin\n",
        "    # #   output = re.sub(r'[A-Za-z]+','', textt)\n",
        "    # #   clean_tokens.append(output)\n",
        "    clean_tokens = custom_tokenize(output)\n",
        "    # clean_tokens = []\n",
        "    # for token in tokens:\n",
        "    #   token.replace('\\u200c','')\n",
        "    #   clean_tokens.append(token)\n",
        "    # # for word in clean_tokens:\n",
        "    # #   if word == '&':\n",
        "    # #     break\n",
        "    # #   syn.append(word)\n",
        "    return clean_tokens\n",
        "  else:\n",
        "    return ' '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XY0aGfFMuFP"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5B5ndBX4bUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46800384-057e-41bb-e849-818284467922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n",
            "nadarim\n"
          ]
        }
      ],
      "source": [
        "syn_list = []\n",
        "for i in range(len(enc)):\n",
        "  try:\n",
        "    syn_list.append(synonyms(enc[1][i]))\n",
        "  except:\n",
        "    print('nadarim')\n",
        "    syn_list.append('nadarim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njHGAlc9xC5o"
      },
      "outputs": [],
      "source": [
        "syn_df = pd.DataFrame(syn_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIkj-ZLQwoVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "ab129242-013b-4609-caa5-4123e9ba9c4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           word             0        1         2            3         4  \\\n",
              "0          آباء         اجداد    اسلاف     پدران     پیشینیان   نیاکان    \n",
              "1         آباجی          آبجی      اخت      باجی        خواهر       دده   \n",
              "2          آباد          برپا     دایر    معمور       پررونق    پیشرفته   \n",
              "3        آبادان          آباد     برپا    پررونق         دایر    معمور    \n",
              "4       آبادانی         آبادی    عمارت    عمران          ترقی     توسعه   \n",
              "...         ...           ...      ...       ...          ...       ...   \n",
              "19891    یک‌ثلث         سه-یک     None      None         None      None   \n",
              "19892      یکجا   روی-هم-رفته     کلاً   مجموعاً      یک-کاسه      None   \n",
              "19893  یک‌جانبه       یک-جهته   یکراهه    یکسویه     یک-طرفه       None   \n",
              "19894    یک‌جهت       هم-آهنگ     همرس     یک-سو         None      None   \n",
              "19895      یکدل        بی-ریا    صمیمی      متفق   متفق-القول      مخلص   \n",
              "\n",
              "                  5         6        7       8  ...    34    35    36    37  \\\n",
              "0              None      None     None    None  ...  None  None  None  None   \n",
              "1            شاباجی   همشیره      None    None  ...  None  None  None  None   \n",
              "2       توسعه-یافته    مترقی    تندرست   سالم   ...  None  None  None  None   \n",
              "3              None      None     None    None  ...  None  None  None  None   \n",
              "4             رونق      آسایش    ترفیه   رفاه   ...  None  None  None  None   \n",
              "...             ...       ...      ...     ...  ...   ...   ...   ...   ...   \n",
              "19891          None      None     None    None  ...  None  None  None  None   \n",
              "19892          None      None     None    None  ...  None  None  None  None   \n",
              "19893          None      None     None    None  ...  None  None  None  None   \n",
              "19894          None      None     None    None  ...  None  None  None  None   \n",
              "19895          None      None     None    None  ...  None  None  None  None   \n",
              "\n",
              "         38    39    40    41    42    43  \n",
              "0      None  None  None  None  None  None  \n",
              "1      None  None  None  None  None  None  \n",
              "2      None  None  None  None  None  None  \n",
              "3      None  None  None  None  None  None  \n",
              "4      None  None  None  None  None  None  \n",
              "...     ...   ...   ...   ...   ...   ...  \n",
              "19891  None  None  None  None  None  None  \n",
              "19892  None  None  None  None  None  None  \n",
              "19893  None  None  None  None  None  None  \n",
              "19894  None  None  None  None  None  None  \n",
              "19895  None  None  None  None  None  None  \n",
              "\n",
              "[19896 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5f09a61-979f-498a-8017-b614485eda4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>آباء</td>\n",
              "      <td>اجداد</td>\n",
              "      <td>اسلاف</td>\n",
              "      <td>پدران</td>\n",
              "      <td>پیشینیان</td>\n",
              "      <td>نیاکان</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>آباجی</td>\n",
              "      <td>آبجی</td>\n",
              "      <td>اخت</td>\n",
              "      <td>باجی</td>\n",
              "      <td>خواهر</td>\n",
              "      <td>دده</td>\n",
              "      <td>شاباجی</td>\n",
              "      <td>همشیره</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>آباد</td>\n",
              "      <td>برپا</td>\n",
              "      <td>دایر</td>\n",
              "      <td>معمور</td>\n",
              "      <td>پررونق</td>\n",
              "      <td>پیشرفته</td>\n",
              "      <td>توسعه-یافته</td>\n",
              "      <td>مترقی</td>\n",
              "      <td>تندرست</td>\n",
              "      <td>سالم</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>آبادان</td>\n",
              "      <td>آباد</td>\n",
              "      <td>برپا</td>\n",
              "      <td>پررونق</td>\n",
              "      <td>دایر</td>\n",
              "      <td>معمور</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>آبادانی</td>\n",
              "      <td>آبادی</td>\n",
              "      <td>عمارت</td>\n",
              "      <td>عمران</td>\n",
              "      <td>ترقی</td>\n",
              "      <td>توسعه</td>\n",
              "      <td>رونق</td>\n",
              "      <td>آسایش</td>\n",
              "      <td>ترفیه</td>\n",
              "      <td>رفاه</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19891</th>\n",
              "      <td>یک‌ثلث</td>\n",
              "      <td>سه-یک</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19892</th>\n",
              "      <td>یکجا</td>\n",
              "      <td>روی-هم-رفته</td>\n",
              "      <td>کلاً</td>\n",
              "      <td>مجموعاً</td>\n",
              "      <td>یک-کاسه</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19893</th>\n",
              "      <td>یک‌جانبه</td>\n",
              "      <td>یک-جهته</td>\n",
              "      <td>یکراهه</td>\n",
              "      <td>یکسویه</td>\n",
              "      <td>یک-طرفه</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19894</th>\n",
              "      <td>یک‌جهت</td>\n",
              "      <td>هم-آهنگ</td>\n",
              "      <td>همرس</td>\n",
              "      <td>یک-سو</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19895</th>\n",
              "      <td>یکدل</td>\n",
              "      <td>بی-ریا</td>\n",
              "      <td>صمیمی</td>\n",
              "      <td>متفق</td>\n",
              "      <td>متفق-القول</td>\n",
              "      <td>مخلص</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19896 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5f09a61-979f-498a-8017-b614485eda4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5f09a61-979f-498a-8017-b614485eda4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5f09a61-979f-498a-8017-b614485eda4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "enc_df = pd.DataFrame({'word':enc[0]})\n",
        "synonyms = pd.concat([enc_df, syn_df], axis=1)\n",
        "synonyms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XgbT2BANbYh"
      },
      "outputs": [],
      "source": [
        "synonyms.to_csv('/content/drive/My Drive/Colab Notebooks/Nikta/Ad Paraphrasing/Bazarol/enc.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DltxMMoGuXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8bdf4de-4e2e-4e14-b5c2-d1b20d704f91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' پهنه', ' جولانگاه', ' رزمگاه', ' زمینه', ' ساحت', ' صحنه',\n",
              "       ' فضا', ' گستره', ' مصاف', ' میدان ', ' حیاط ', ' بیابان', ' صحرا',\n",
              "       None, None, None, None, None, None, None, None, None, None, None,\n",
              "       None, None, None, None, None, None, None, None, None, None, None,\n",
              "       None, None, None, None, None, None, None, None, None], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "token = \"عرصه\"\n",
        "sdf = synonyms.query('word ==' + '\"' + str(token) + '\"')\n",
        "df = sdf.drop([\"word\"], axis=1)\n",
        "np.array(df)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Vavy_-O9iK"
      },
      "source": [
        "# Simple Synonym Replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mP_VCWD3iUM"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# def replacement(t):\n",
        "#   output = t\n",
        "#   valid_pos = pos(t)\n",
        "#   valid_ner = ner(t)\n",
        "#   goodtogo = intersection(valid_pos,valid_ner)\n",
        "#   tokens = word_tokenize(t)\n",
        "#   for token in tokens:\n",
        "#     if token in goodtogo:\n",
        "#       sdf = synonyms.query('word ==' + '\"' + str(token) + '\"')\n",
        "#       if len(sdf) == 0:\n",
        "#         continue\n",
        "#       # print(sdf)\n",
        "#       df = sdf.drop([\"word\"], axis=1)\n",
        "#       nump = np.array(df) \n",
        "#       slist = []\n",
        "#       for i in range(0, len(nump)):\n",
        "#         w = nump[0][i]\n",
        "#         if w:\n",
        "#           if w!= 'nadarim':\n",
        "#             print(token)\n",
        "#             print(w)\n",
        "#             slist.append(w)\n",
        "#       if len(slist) != 0 :\n",
        "#         print('Changed')\n",
        "#         rand = random.randint(0, len(slist)-1)\n",
        "#         output = output.replace(token,slist[rand])\n",
        "#   return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFqUFywhAJF_"
      },
      "outputs": [],
      "source": [
        "# test['text'][1] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apIE_Ndj_459"
      },
      "outputs": [],
      "source": [
        "# replacement(test['text'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5copKERxkfb"
      },
      "outputs": [],
      "source": [
        "#bege chantaro avaz karde va bege kudumaro bara check masool daftar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcV2jJ7PRcYP"
      },
      "source": [
        "# Synonym Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WP0VuelRr36"
      },
      "source": [
        "## Frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MEdUKmtRfrb"
      },
      "outputs": [],
      "source": [
        "#treshold 0.0002\n",
        "tresh = 0.0001 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdWq9IOkR4EE"
      },
      "outputs": [],
      "source": [
        "def frequency_check(word, group_name):\n",
        "  freq = 0\n",
        "  gp_df = sentences1.query('gp ==' + '\"' + str(group_name) + '\"')\n",
        "  for index, row in gp_df.iterrows():\n",
        "    text = str(row['text'])\n",
        "    count = text.count(word)\n",
        "    freq = freq + count\n",
        "  return freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0suKKUBSuny"
      },
      "outputs": [],
      "source": [
        "def word_num(group_name):\n",
        "  freq = 0\n",
        "  gp_df = sentences1.query('gp ==' + '\"' + str(group_name) + '\"')\n",
        "  for index, row in gp_df.iterrows():\n",
        "    text = str(row['text'])\n",
        "    tokens = word_tokenize(text)\n",
        "    freq = freq + len(tokens)\n",
        "  return freq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gk82ksfUYuQ"
      },
      "source": [
        "### Synonym replacement with frequency check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHugPXl_UfFD"
      },
      "outputs": [],
      "source": [
        "loop_control = 20\n",
        "import random\n",
        "def replacement2(t,group_name):\n",
        "  changed_tokens = []\n",
        "  changed_synonyms = []\n",
        "  output = t\n",
        "  valid_pos = pos(t)\n",
        "  valid_ner = ner(t)\n",
        "  goodtogo = intersection(valid_pos,valid_ner)\n",
        "  tokens = word_tokenize(t)\n",
        "  for token in tokens:\n",
        "    if token in goodtogo:\n",
        "      sdf = synonyms.query('word ==' + '\"' + str(token) + '\"')\n",
        "      if len(sdf) == 0:\n",
        "        continue\n",
        "      # print(sdf)\n",
        "      df = sdf.drop([\"word\"], axis=1)\n",
        "      nump = np.array(df) \n",
        "      slist = []\n",
        "      for i in range(0, len(nump[0])):\n",
        "        w = nump[0][i]\n",
        "        if w:\n",
        "          if w!= 'nadarim':\n",
        "            slist.append(w)\n",
        "      #print(slist)\n",
        "      if len(slist) != 0 :\n",
        "        rand = random.randint(0, len(slist)-1)\n",
        "        # print(str(slist[rand]))\n",
        "        check = frequency_check(str(slist[rand]),group_name)/word_num(group_name)\n",
        "        # print(check)\n",
        "        i=0\n",
        "        while(i <= loop_control):\n",
        "          if  check > tresh:\n",
        "            #print('Changed')\n",
        "            # print(slist[rand])\n",
        "            output = output.replace(token,slist[rand])\n",
        "            changed_tokens.append(token)\n",
        "            changed_synonyms.append(slist[rand])\n",
        "            i = loop_control\n",
        "          i = i +1\n",
        "  return output,changed_tokens,changed_synonyms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcitgPFaVguB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9776238-3689-43e2-8beb-b7d28c0a1b93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002155621149582961"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "# Test Treshold\n",
        "word = 'جام'\n",
        "group_name = 'لوازم'\n",
        "frequency_check(word,group_name)/word_num(group_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvoFRWAqpC2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "73e9a251-0142-419b-ea12-39358f2bfaf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text           gp\n",
              "0  ردیاب خودرو مدل 104 ..ردیاب جی اس مدل 104 انوا...  وسایل نقلیه\n",
              "1  میتوانم نرم افزار ارسال جستجوی سایت رایگان اخت...     کامپیوتر"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fde51d25-315f-468e-89d3-5801a3e0171d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>gp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ردیاب خودرو مدل 104 ..ردیاب جی اس مدل 104 انوا...</td>\n",
              "      <td>وسایل نقلیه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>میتوانم نرم افزار ارسال جستجوی سایت رایگان اخت...</td>\n",
              "      <td>کامپیوتر</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fde51d25-315f-468e-89d3-5801a3e0171d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fde51d25-315f-468e-89d3-5801a3e0171d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fde51d25-315f-468e-89d3-5801a3e0171d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "shuf = sentences1.sample(frac = 1)\n",
        "testcase = shuf[:2]\n",
        "testcase = testcase.reset_index(drop=True)\n",
        "testcase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNy4pAVAMnAP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "changed_tokens_all = []\n",
        "changed_synonyms_all = []\n",
        "changed_texts_all = []\n",
        "texts_all = [] \n",
        "group_names = []\n",
        "for i in range(len(testcase)):\n",
        "  if len(testcase['text'][i]) >= 512:\n",
        "    continue\n",
        "  try:\n",
        "    output,changed_tokens,changed_synonyms = replacement2(testcase['text'][i],testcase['gp'][i])\n",
        "    texts_all.append(testcase['text'][i])\n",
        "    changed_texts_all.append(output)\n",
        "    changed_synonyms_all.append(changed_synonyms)\n",
        "    changed_tokens_all.append(changed_tokens)\n",
        "    group_names.append(testcase['gp'][i])\n",
        "  except:\n",
        "    print(i)\n",
        "result = pd.DataFrame({'Group': group_names, 'Text': texts_all, 'Changed_Text': changed_texts_all, 'Changed_words': changed_tokens_all, 'Changed_Synonyms': changed_synonyms_all})\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tBcYj8CeGdV",
        "outputId": "aec87f16-0d77-405a-fed9-cb0fd7174351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.273941040039062"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2bKeKZo2g2Q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mexMffd02g4w"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Synonym Replacement Pipeline.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}